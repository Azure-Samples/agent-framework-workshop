{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3caedd7e",
   "metadata": {},
   "source": [
    "## Introduction to Human In The Loop in Agent Framework\n",
    "\n",
    "Workflows in the Microsoft Agent Framework allow developers to design, monitor, and control how multiple AI agents and logic components interact to complete complex tasks. They bring structure, flexibility, and transparency to agent-driven applications.\n",
    "\n",
    "One of the ways to bring in control and manage agent workflows is to add human approvals. When agents require any user input, for example to approve a function call, this is referred to as a **human-in-the-loop** pattern. \n",
    "\n",
    "An agent run that requires user input will complete with a response that indicates what input is required from the user instead of completing with a final answer. The caller of the agent is then responsible for getting the required input from the user and passing it back to the agent as part of a new agent run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a926c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Example 1 - Function Tools with Human-In-The-Loop approvals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d01c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "load_dotenv()\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat_client=AzureOpenAIChatClient(\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=api_version,\n",
    "        deployment_name=deployment,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3409f049",
   "metadata": {},
   "source": [
    "#### Key components\n",
    "\n",
    "1. `@ai_function(approval_mode=\"always_require\")`:\n",
    "\n",
    "Use the `@ai_function` decorator to specify metadata. To create a function that requires approval, you can use the `approval_mode` parameter so the agent can pause and ask for user approval.\n",
    "\n",
    "2. `user_input_requests`:\n",
    "\n",
    "Since you now have a function that requires approval, the agent can respond with a request for approval instead of executing the function directly and returning the result. \n",
    "\n",
    "You should check the response for any user input requests, which indicates that the agent requires user approval for a function. \n",
    "\n",
    "The details of the function call including name and arguments can be found in the `function_call` property on the user input request:\n",
    "\n",
    "```python\n",
    "    user_input_needed.function_call.name\n",
    "    user_input_needed.function_call.arguments\n",
    "```\n",
    "\n",
    "3. `create_response()`:\n",
    "\n",
    "Once the user has provided their input, you can create a response using the `create_response` method on the user input request. Pass True to approve the function call, or False to reject it.\n",
    "\n",
    "The response should then be passed to the agent in a new ChatMessage:\n",
    "\n",
    "```python\n",
    "    approval_message = ChatMessage(\n",
    "    role=Role.USER, \n",
    "        contents=[user_input_needed.create_response(user_approval)]\n",
    "    )\n",
    "```\n",
    "`.create_response(user_approval)` embeds the approval decision inside a message the framework understands.\n",
    "\n",
    "4. **Resuming Execution:**\n",
    "\n",
    "After collecting user approval decisions for pending function calls, you need to resume the agent's execution by reconstructing the conversation history. To resume execution, you must provide both the agent's function call requests and the user's approval responses as ChatMessage objects:\n",
    "    \n",
    "```python\n",
    "    final_result = await agent1.run([\n",
    "    \"What is the detailed weather like in Amsterdam?\",\n",
    "    ChatMessage(role=Role.ASSISTANT, contents=[user_input_needed]),\n",
    "    approval_message\n",
    "    ])\n",
    "```\n",
    "By providing both messages, you're reconstructing the conversation flow: the agent proposed an action (ASSISTANT), and the user responded to that proposal (USER).\n",
    "\n",
    "> *Note*: In this example, if the user rejects a function call (`user_approval = False`), the agent doesn't simply fail. Instead, it attempts to fulfill the user's intent using alternative available tool - `get_weather`. In this example, if `get_weather_detail` is rejected, the agent may fall back to calling `get_weather` (which doesn't require approval) to still provide some weather information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2472de7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "<class 'agent_framework.azure._chat_client.AzureOpenAIChatClient'> service failed to complete the prompt: Error code: 403 - {'error': {'code': 'AuthenticationTypeDisabled', 'message': 'Key based authentication is disabled for this resource.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/openai/_chat_client.py:78\u001b[39m, in \u001b[36mOpenAIBaseChatClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# execute and process\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_response_from_openai(\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **options_dict), chat_options\n\u001b[32m     79\u001b[39m     )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequestError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2677\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2679\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2680\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2681\u001b[39m         {\n\u001b[32m   2682\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2683\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2684\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2685\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2686\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2687\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2688\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2689\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2690\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2691\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2692\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2693\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2694\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2695\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2696\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2697\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2698\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   2700\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2701\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2702\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2703\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2707\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2708\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2709\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2710\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2711\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2712\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2713\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2714\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2715\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2716\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2717\u001b[39m         },\n\u001b[32m   2718\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2719\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2720\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2721\u001b[39m     ),\n\u001b[32m   2722\u001b[39m     options=make_request_options(\n\u001b[32m   2723\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2724\u001b[39m     ),\n\u001b[32m   2725\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2726\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2727\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2728\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py:1797\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1794\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1795\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1796\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1797\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py:1597\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1596\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1597\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': {'code': 'AuthenticationTypeDisabled', 'message': 'Key based authentication is disabled for this resource.'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe weather in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is cloudy with a high of 15°C, humidity 88%.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m agent = ChatAgent(\n\u001b[32m     17\u001b[39m     chat_client=chat_client,\n\u001b[32m     18\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mWeatherAgent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful weather assistant.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     tools=[get_weather_detail, get_weather],\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(\u001b[33m\"\u001b[39m\u001b[33mWhat is the detailed weather like in Amsterdam?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.user_input_requests:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mApproval required:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py:1249\u001b[39m, in \u001b[36muse_agent_middleware.<locals>.middleware_enabled_run\u001b[39m\u001b[34m(self, messages, thread, middleware, **kwargs)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m AgentRunResponse()\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# No middleware, execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_run(\u001b[38;5;28mself\u001b[39m, normalized_messages, thread=thread, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/observability.py:1343\u001b[39m, in \u001b[36m_trace_agent_run.<locals>.trace_run\u001b[39m\u001b[34m(self, messages, thread, **kwargs)\u001b[39m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_func(\u001b[38;5;28mself\u001b[39m, messages=messages, thread=thread, **kwargs)\n\u001b[32m   1344\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mchat_options\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   1345\u001b[39m attributes = _get_span_attributes(\n\u001b[32m   1346\u001b[39m     operation_name=OtelAttr.AGENT_INVOKE_OPERATION,\n\u001b[32m   1347\u001b[39m     provider_name=provider_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1353\u001b[39m     **filtered_kwargs,\n\u001b[32m   1354\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_agents.py:886\u001b[39m, in \u001b[36mChatAgent.run\u001b[39m\u001b[34m(self, messages, thread, allow_multiple_tool_calls, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_chat_options, **kwargs)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;66;03m# Filter chat_options from kwargs to prevent duplicate keyword argument\u001b[39;00m\n\u001b[32m    885\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mchat_options\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chat_client.get_response(\n\u001b[32m    887\u001b[39m     messages=thread_messages,\n\u001b[32m    888\u001b[39m     chat_options=co,\n\u001b[32m    889\u001b[39m     **filtered_kwargs,\n\u001b[32m    890\u001b[39m )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_thread_with_type_and_conversation_id(thread, response.conversation_id)\n\u001b[32m    894\u001b[39m \u001b[38;5;66;03m# Ensure that the author name is set for each message in the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_tools.py:1818\u001b[39m, in \u001b[36m_handle_function_calls_response.<locals>.decorator.<locals>.function_invocation_wrapper\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1816\u001b[39m \u001b[38;5;66;03m# Filter out internal framework kwargs before passing to clients.\u001b[39;00m\n\u001b[32m   1817\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mthread\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m-> \u001b[39m\u001b[32m1818\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, messages=prepped_messages, **filtered_kwargs)\n\u001b[32m   1819\u001b[39m \u001b[38;5;66;03m# if there are function calls, we will handle them first\u001b[39;00m\n\u001b[32m   1820\u001b[39m function_results = {\n\u001b[32m   1821\u001b[39m     it.call_id \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m response.messages[\u001b[32m0\u001b[39m].contents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, FunctionResultContent)\n\u001b[32m   1822\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/observability.py:1071\u001b[39m, in \u001b[36m_trace_get_response.<locals>.decorator.<locals>.trace_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1070\u001b[39m     \u001b[38;5;66;03m# If model_id diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\n\u001b[32m   1072\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1073\u001b[39m         messages=messages,\n\u001b[32m   1074\u001b[39m         **kwargs,\n\u001b[32m   1075\u001b[39m     )\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.additional_properties:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28mself\u001b[39m.additional_properties[\u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m] = _get_token_usage_histogram()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py:1367\u001b[39m, in \u001b[36muse_chat_middleware.<locals>.middleware_enabled_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;66;03m# If no chat middleware, use original method\u001b[39;00m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_middleware_list:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_get_response(\u001b[38;5;28mself\u001b[39m, messages, **kwargs)\n\u001b[32m   1369\u001b[39m \u001b[38;5;66;03m# Create pipeline and execute with middleware\u001b[39;00m\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOptions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:581\u001b[39m, in \u001b[36mBaseChatClient.get_response\u001b[39m\u001b[34m(self, messages, allow_multiple_tool_calls, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_properties, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_tool_choice(chat_options=chat_options)\n\u001b[32m    580\u001b[39m filtered_kwargs = \u001b[38;5;28mself\u001b[39m._filter_internal_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_response(messages=prepped_messages, chat_options=chat_options, **filtered_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/openai/_chat_client.py:91\u001b[39m, in \u001b[36mOpenAIBaseChatClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m     87\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m         inner_exception=ex,\n\u001b[32m     89\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m     92\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     93\u001b[39m         inner_exception=ex,\n\u001b[32m     94\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: <class 'agent_framework.azure._chat_client.AzureOpenAIChatClient'> service failed to complete the prompt: Error code: 403 - {'error': {'code': 'AuthenticationTypeDisabled', 'message': 'Key based authentication is disabled for this resource.'}}"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from agent_framework import ai_function, ChatMessage, Role, ChatAgent \n",
    "\n",
    "\n",
    "@ai_function\n",
    "def get_weather(location: Annotated[str, \"The city and state, e.g. San Francisco, CA\"]) -> str:\n",
    "    \"\"\"Get the current weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is sunny with a high of 30°C.\"\n",
    "\n",
    "@ai_function(approval_mode=\"always_require\")\n",
    "def get_weather_detail(location: Annotated[str, \"The city and state, e.g. San Francisco, CA\"]) -> str:\n",
    "    \"\"\"Get detailed weather information for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C, humidity 88%.\"\n",
    "\n",
    "\n",
    "agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    name=\"WeatherAgent\",\n",
    "    instructions=\"You are a helpful weather assistant.\",\n",
    "    tools=[get_weather_detail, get_weather],\n",
    ")\n",
    "\n",
    "result = await agent.run(\"What is the detailed weather like in Amsterdam?\")\n",
    "\n",
    "if result.user_input_requests:\n",
    "    print(\"Approval required:\")\n",
    "    for user_input_needed in result.user_input_requests:\n",
    "        print(f\"Function: {user_input_needed.function_call.name}\")\n",
    "        print(f\"Arguments: {user_input_needed.function_call.arguments}\")\n",
    "        \n",
    "    # Get user approval (non-interactive here)\n",
    "    user_approval = True \n",
    "\n",
    "    # Create the approval response\n",
    "    approval_message = ChatMessage(\n",
    "        role=Role.USER, \n",
    "        contents=[user_input_needed.create_response(user_approval)]\n",
    "    )\n",
    "\n",
    "    final_result = await agent.run([\n",
    "        \"What is the detailed weather like in Amsterdam?\",\n",
    "        ChatMessage(role=Role.ASSISTANT, contents=[user_input_needed]),\n",
    "        approval_message\n",
    "    ])\n",
    "\n",
    "print(final_result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785b131",
   "metadata": {},
   "source": [
    "In the example above, during the first agent run, the agent doesn't complete execution because it identifies that `get_weather_detail` which requires approval needs to be called. Instead of executing the function, the first `agent.run()` call completes immediately and returns the pending function call in `result.user_input_requests`.\n",
    "\n",
    "We then collect the user's approval decision and resume execution via the second `agent.run()` call with the complete conversation history, including the approval response. This processes the approval decision and either executes the function (if approved) or adapts its strategy (if rejected) to provide a final response. This pattern ensures human oversight while giving your application full control over how approval requests are presented to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed67f8b",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "First, let's define our agent functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318380ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ai_function\n",
    "from typing import Annotated\n",
    "import random\n",
    "\n",
    "@ai_function(approval_mode=\"always_require\")\n",
    "def submit_payment(\n",
    "    amount: Annotated[float, \"Payment amount in USD\"],\n",
    "    recipient: Annotated[str, \"Recipient name or vendor ID\"],\n",
    "    reference: Annotated[str, \"Short description for the payment reference\"],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Submit a payment request to the external payments system.\n",
    "\n",
    "    This operation has financial impact and should always be reviewed\n",
    "    and approved by a human before it is executed.\n",
    "    \"\"\"\n",
    "    # In a real scenario this would call an external payments API.\n",
    "    # Here we just simulate the side effect.\n",
    "    return (\n",
    "        f\"Payment of ${amount:.2f} to '{recipient}' has been submitted \"\n",
    "        f\"with reference '{reference}'.\"\n",
    "    )\n",
    "\n",
    "@ai_function(\n",
    "    name=\"get_account_balance\",\n",
    "    description=\"Retrieves the current account balance for the user in USD\"\n",
    ")\n",
    "def get_account_balance() -> float:\n",
    "    \"\"\"\n",
    "    Get the current account balance for the user.\n",
    "    \n",
    "    Returns:\n",
    "        float: The account balance in USD (numeric value only, no formatting).\n",
    "    \n",
    "    This operation is read-only and does not require approval.\n",
    "    \"\"\"\n",
    "    # Generate a random balance between 1000 and 5000 USD\n",
    "    balance = random.uniform(1000, 5000)\n",
    "    return round(balance, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649caa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FinanceAgent - Interactive Session ===\n",
      "Type 'exit' or 'quit' to end the conversation\n",
      "\n",
      "\n",
      "Agent: "
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "<class 'agent_framework.azure._chat_client.AzureOpenAIChatClient'> service failed to complete the prompt: Error code: 403 - {'error': {'code': 'AuthenticationTypeDisabled', 'message': 'Key based authentication is disabled for this resource.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/openai/_chat_client.py:78\u001b[39m, in \u001b[36mOpenAIBaseChatClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# execute and process\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_response_from_openai(\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **options_dict), chat_options\n\u001b[32m     79\u001b[39m     )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequestError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2677\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2679\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2680\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2681\u001b[39m         {\n\u001b[32m   2682\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2683\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2684\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2685\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2686\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2687\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2688\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2689\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2690\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2691\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2692\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2693\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2694\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2695\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2696\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2697\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2698\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2699\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   2700\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2701\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2702\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2703\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2707\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2708\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2709\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2710\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2711\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2712\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2713\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2714\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2715\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2716\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2717\u001b[39m         },\n\u001b[32m   2718\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2719\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2720\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2721\u001b[39m     ),\n\u001b[32m   2722\u001b[39m     options=make_request_options(\n\u001b[32m   2723\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2724\u001b[39m     ),\n\u001b[32m   2725\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2726\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2727\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2728\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py:1797\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1794\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1795\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1796\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1797\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py:1597\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1596\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1597\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': {'code': 'AuthenticationTypeDisabled', 'message': 'Key based authentication is disabled for this resource.'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAgent: \u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(user_input, thread=thread)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.user_input_requests:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== APPROVALS REQUIRED ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py:1249\u001b[39m, in \u001b[36muse_agent_middleware.<locals>.middleware_enabled_run\u001b[39m\u001b[34m(self, messages, thread, middleware, **kwargs)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m AgentRunResponse()\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# No middleware, execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_run(\u001b[38;5;28mself\u001b[39m, normalized_messages, thread=thread, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/observability.py:1343\u001b[39m, in \u001b[36m_trace_agent_run.<locals>.trace_run\u001b[39m\u001b[34m(self, messages, thread, **kwargs)\u001b[39m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_func(\u001b[38;5;28mself\u001b[39m, messages=messages, thread=thread, **kwargs)\n\u001b[32m   1344\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mchat_options\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   1345\u001b[39m attributes = _get_span_attributes(\n\u001b[32m   1346\u001b[39m     operation_name=OtelAttr.AGENT_INVOKE_OPERATION,\n\u001b[32m   1347\u001b[39m     provider_name=provider_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1353\u001b[39m     **filtered_kwargs,\n\u001b[32m   1354\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_agents.py:886\u001b[39m, in \u001b[36mChatAgent.run\u001b[39m\u001b[34m(self, messages, thread, allow_multiple_tool_calls, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_chat_options, **kwargs)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;66;03m# Filter chat_options from kwargs to prevent duplicate keyword argument\u001b[39;00m\n\u001b[32m    885\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mchat_options\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chat_client.get_response(\n\u001b[32m    887\u001b[39m     messages=thread_messages,\n\u001b[32m    888\u001b[39m     chat_options=co,\n\u001b[32m    889\u001b[39m     **filtered_kwargs,\n\u001b[32m    890\u001b[39m )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_thread_with_type_and_conversation_id(thread, response.conversation_id)\n\u001b[32m    894\u001b[39m \u001b[38;5;66;03m# Ensure that the author name is set for each message in the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_tools.py:1818\u001b[39m, in \u001b[36m_handle_function_calls_response.<locals>.decorator.<locals>.function_invocation_wrapper\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1816\u001b[39m \u001b[38;5;66;03m# Filter out internal framework kwargs before passing to clients.\u001b[39;00m\n\u001b[32m   1817\u001b[39m filtered_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mthread\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m-> \u001b[39m\u001b[32m1818\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, messages=prepped_messages, **filtered_kwargs)\n\u001b[32m   1819\u001b[39m \u001b[38;5;66;03m# if there are function calls, we will handle them first\u001b[39;00m\n\u001b[32m   1820\u001b[39m function_results = {\n\u001b[32m   1821\u001b[39m     it.call_id \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m response.messages[\u001b[32m0\u001b[39m].contents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, FunctionResultContent)\n\u001b[32m   1822\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/observability.py:1071\u001b[39m, in \u001b[36m_trace_get_response.<locals>.decorator.<locals>.trace_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1070\u001b[39m     \u001b[38;5;66;03m# If model_id diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\n\u001b[32m   1072\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1073\u001b[39m         messages=messages,\n\u001b[32m   1074\u001b[39m         **kwargs,\n\u001b[32m   1075\u001b[39m     )\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.additional_properties:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28mself\u001b[39m.additional_properties[\u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m] = _get_token_usage_histogram()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_middleware.py:1367\u001b[39m, in \u001b[36muse_chat_middleware.<locals>.middleware_enabled_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;66;03m# If no chat middleware, use original method\u001b[39;00m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_middleware_list:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_get_response(\u001b[38;5;28mself\u001b[39m, messages, **kwargs)\n\u001b[32m   1369\u001b[39m \u001b[38;5;66;03m# Create pipeline and execute with middleware\u001b[39;00m\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOptions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:581\u001b[39m, in \u001b[36mBaseChatClient.get_response\u001b[39m\u001b[34m(self, messages, allow_multiple_tool_calls, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_properties, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_tool_choice(chat_options=chat_options)\n\u001b[32m    580\u001b[39m filtered_kwargs = \u001b[38;5;28mself\u001b[39m._filter_internal_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_response(messages=prepped_messages, chat_options=chat_options, **filtered_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/af_project/agent-framework-workshop/.venv/lib/python3.12/site-packages/agent_framework/openai/_chat_client.py:91\u001b[39m, in \u001b[36mOpenAIBaseChatClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m     87\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m         inner_exception=ex,\n\u001b[32m     89\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m     92\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     93\u001b[39m         inner_exception=ex,\n\u001b[32m     94\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: <class 'agent_framework.azure._chat_client.AzureOpenAIChatClient'> service failed to complete the prompt: Error code: 403 - {'error': {'code': 'AuthenticationTypeDisabled', 'message': 'Key based authentication is disabled for this resource.'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from agent_framework import ChatAgent, ChatMessage, Role\n",
    "\n",
    "# Stateful agent wired to Azure OpenAI plus both banking tools\n",
    "agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    name=\"FinanceAgent\",\n",
    "    instructions=(\n",
    "        \"You are an agent from Contoso Bank. You assist users with financial operations \"\n",
    "        \"and provide clear explanations. For transfers only amount, recipient name, and reference are needed.\"\n",
    "    ),\n",
    "    tools=[submit_payment, get_account_balance],\n",
    ")\n",
    "\n",
    "# Preserve conversation memory across the entire console session\n",
    "thread = agent.get_new_thread()\n",
    "print(\"=== FinanceAgent - Interactive Session ===\")\n",
    "print(\"Type 'exit' or 'quit' to end the conversation\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in (\"exit\", \"quit\"):\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "    print(\"\\nAgent: \", end=\"\", flush=True)\n",
    "    result = await agent.run(user_input, thread=thread)\n",
    "\n",
    "    if result.user_input_requests:\n",
    "        print(\"\\n\\n=== APPROVALS REQUIRED ===\")\n",
    "        approval_messages: list[ChatMessage] = []\n",
    "\n",
    "        # Surface every pending tool call and gather a decision per call\n",
    "        for req in result.user_input_requests:\n",
    "            print(f\"- Function: {req.function_call.name}\")\n",
    "            print(f\"  Arguments: {req.function_call.arguments}\")\n",
    "            approved = input(f\"Approve '{req.function_call.name}'? (yes/no): \").strip().lower() == \"yes\"\n",
    "\n",
    "            # Encode the approval/denial into a ChatMessage the framework consumes\n",
    "            approval_messages.append(\n",
    "                ChatMessage(role=Role.USER, contents=[req.create_response(approved)])\n",
    "            )\n",
    "\n",
    "        # Resume the prior run once all approvals are ready\n",
    "        followup = await agent.run(approval_messages, thread=thread, prior_run=result)\n",
    "        print(\"\\nAgent:\", followup.text)\n",
    "        print(\"\\nUser:\", result.text)\n",
    "\n",
    "    else:\n",
    "        print(result.text)\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(type(followup))\n",
    "\n",
    "print(\"RESULT:\",result.messages)\n",
    "for msg in result.messages:\n",
    "    print(f\" - {msg.role}: {msg.text}\")\n",
    "\n",
    "messages = await thread.message_store.list_messages()\n",
    "print(\"FOLLOWUP:\", followup)\n",
    "for msg in messages:\n",
    "    print(f\" - {msg.role}: {msg.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b1871",
   "metadata": {},
   "source": [
    "### Request and Response\n",
    "\n",
    "#### Recap - Message-Centric Execution Model\n",
    "\n",
    "In AF, agent execution is fundamentally about the **data flow** - a workflow will keep running as long as there is data being passed. Agents don't \"call\" each other or pass control in a traditional procedural sense. Instead, they communicate through typed messages flowing between executors through edges.\n",
    "\n",
    "**Executors** are where computation happens. When an executor emits a message, it flows along the edges to downstream executors which activate when their dependent data becomes available.\n",
    "\n",
    "Agents communicate with applications via different message content types (`TextContent`, `FunctionCallContent`, `FunctionApprovalRequestContent`, etc.). Messages are represented by the `ChatMessage` class and all content type classes inherit from the base `BaseContent` class.\n",
    "\n",
    "For a detailed list of available content types and their usage, refer to the folowing [documentation](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/running-agents?pivots=programming-language-python).\n",
    "\n",
    "\n",
    "#### User Approval Content\n",
    "\n",
    "The content of the message can also be used to let the application approve or disapprove some actions the agent wants to take.\n",
    "**User Approval Content** type enables human-in-the-loop approvals within the standard message flow.\n",
    "\n",
    "\n",
    "The approval mechanism intercepts the normal tool invocation flow, pausing execution until human approval is granted or denied:\n",
    "\n",
    "<img src=\"images/reqresp.png\" alt=\"User Approval Content Type\" style=\"width:70%; height:40%; margin:20px auto\">\n",
    "\n",
    "When a ChatAgent needs to invoke a Tool that requires approval:\n",
    "\n",
    "1. **Initial Inference**: The ChatAgent uses the Model to make an inference and determines it needs to invoke the Tool.\n",
    "\n",
    "2. **Approval Request**: Before executing, the Tool sends a request back to the ChatAgent, which surfaces to the Application as `FunctionApprovalRequestContent` (a special ChatMessage content type).\n",
    "\n",
    "3. **User Response**: The Application presents this approval request to the user, who responds (Yes/No). This response is sent back to the ChatAgent as `FunctionApprovalResponseContent`.\n",
    "\n",
    "4. **Tool Execution**: Once the ChatAgent receives approval, the Tool executes and returns its result to the ChatAgent.\n",
    "\n",
    "5. **Final Inference**: The Model makes another inference using the Tool's result to generate a natural language response as `TextContent`.\n",
    "\n",
    "6. **Complete Response**: The Application receives both the `FunctionResultContent` (the raw tool output) and the `TextContent` (the Model's interpretation of that result).\n",
    "\n",
    "#### User Approval Importance\n",
    "\n",
    "User approvals are necessary in many cases, especially when tool execution involves external resources or has side effects. Common scenarios include:\n",
    "\n",
    "- **Irreversible operations**: Data deletion, financial transactions, resource provisioning\n",
    "- **External system access**: Database modifications, API calls, file system operations\n",
    "- **Security-sensitive actions**: Credential access, permission changes, privileged operations\n",
    "\n",
    "When a tool requires approval, the agent pauses execution and transfers control to the application. The agent preserves its state (conversation history, pending actions, context) and waits for the application's decision before proceeding. This mechanism ensures critical operations require explicit human authorization while maintaining the agent's execution context for immediate resumption.\n",
    "\n",
    "As covered in Chapter 1, **Agent Middleware** provides a general-purpose mechanism for intercepting agent interactions at three levels: agent (intercepts entire agent execution), function (intercepts individual tool invocations), and chat (intercepts LLM calls). You can think of the process of user approval during tool invocation as *tool middleware*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4405d04",
   "metadata": {},
   "source": [
    "TODO1 - requests and responses:\n",
    "https://learn.microsoft.com/en-us/agent-framework/tutorials/workflows/requests-and-responses?pivots=programming-language-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67abda",
   "metadata": {},
   "source": [
    "TODO2 - https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/workflows/agents/workflow_as_agent_human_in_the_loop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a67d07",
   "metadata": {},
   "source": [
    "TODO3 - https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/workflows/human-in-the-loop/guessing_game_with_human_input.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

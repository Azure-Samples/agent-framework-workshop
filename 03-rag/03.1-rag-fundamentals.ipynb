{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Chapter 3.1: RAG Fundamentals\n",
    "\n",
    "In this notebook, you'll learn how to build **Retrieval-Augmented Generation (RAG)** systems from the ground up. We'll start by creating a search index programmatically, then build RAG manually to understand the mechanics before showing how function tools can give agents retrieval capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. Create an Azure AI Search index programmatically using Python\n",
    "2. Understand the RAG pattern and why it's essential for enterprise AI\n",
    "3. Build a \"raw\" RAG implementation manually to feel the complexity\n",
    "4. Wrap search as a function tool for agent-controlled retrieval\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this notebook, complete the setup guide: `03.0-setup-guide.md`\n",
    "\n",
    "You should have:\n",
    "- An Azure AI Search service created\n",
    "- A Storage account with blob container\n",
    "- Proper permissions configured\n",
    "- Environment variables in your `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup & Validation\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from workshop_utils import validate_env\n",
    "validate_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Programmatic Index Setup\n",
    "\n",
    "Instead of using the Azure Portal wizard, we'll create our search index using Python. This approach is:\n",
    "\n",
    "- **Reproducible** - Run the same code in any environment\n",
    "- **Version controlled** - Index definitions live with your code\n",
    "- **CI/CD friendly** - Automate index creation in pipelines\n",
    "\n",
    "### Step 1.1: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "load-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Endpoint: https://maf-workshop-ai-search.search.windows.net\n",
      "Index Name: test-index-2\n",
      "OpenAI Endpoint: https://aoai-sweden-gbb-dev.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search configuration\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"SEARCH_API_KEY\")\n",
    "index_name = 'test-index-2'\n",
    "\n",
    "# Azure OpenAI configuration (same as other notebooks)\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Search Endpoint: {search_endpoint}\")\n",
    "print(f\"Index Name: {index_name}\")\n",
    "print(f\"OpenAI Endpoint: {openai_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-2",
   "metadata": {},
   "source": [
    "### Step 1.2: Define the Index Schema\n",
    "\n",
    "An Azure AI Search index consists of:\n",
    "- **Fields** - The data structure (like database columns)\n",
    "- **Vector Search Configuration** - Settings for embedding-based search\n",
    "- **Semantic Configuration** - Settings for AI-powered ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "define-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index schema defined with 5 fields\n",
      "Fields: ['chunk_id', 'parent_id', 'chunk', 'title', 'text_vector']\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Define the index fields (matching Azure AI Search portal wizard schema)\n",
    "# Field names: chunk_id, parent_id, chunk, title, text_vector\n",
    "fields = [\n",
    "    SearchField(\n",
    "        name=\"chunk_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        sortable=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"parent_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,  # For filtering chunks by source document\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"chunk\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"text_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=3072,  # text-embedding-3-large dimension\n",
    "        vector_search_profile_name=f\"{index_name}-vector-profile\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Configure vector search (matching portal wizard settings)\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=f\"{index_name}-algorithm\",\n",
    "            parameters=HnswParameters(\n",
    "                metric=\"cosine\",\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=f\"{index_name}-vector-profile\",\n",
    "            algorithm_configuration_name=f\"{index_name}-algorithm\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Configure semantic search (matching portal wizard)\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=f\"{index_name}-semantic-configuration\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[SemanticField(field_name=\"chunk\")],\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "semantic_search = SemanticSearch(\n",
    "    default_configuration_name=f\"{index_name}-semantic-configuration\",\n",
    "    configurations=[semantic_config],\n",
    ")\n",
    "\n",
    "# Create the index definition\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search,\n",
    ")\n",
    "\n",
    "print(f\"Index schema defined with {len(fields)} fields\")\n",
    "print(f\"Fields: {[f.name for f in fields]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-3",
   "metadata": {},
   "source": [
    "### Step 1.3: Create the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "create-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Index 'test-index-2' created/updated successfully\n"
     ]
    }
   ],
   "source": [
    "# Create the index client\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=AzureKeyCredential(search_key),\n",
    ")\n",
    "\n",
    "# Create or update the index\n",
    "try:\n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f\"âœ… Index '{result.name}' created/updated successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-4",
   "metadata": {},
   "source": [
    "### Step 1.4: Load and Chunk Documents\n",
    "\n",
    "We need to:\n",
    "1. Read the PDF documents from `data/index1/`\n",
    "2. Split them into chunks\n",
    "3. Generate embeddings for each chunk\n",
    "4. Upload to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "load-documents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: PerksPlus.pdf\n",
      "Processing: role_library.pdf\n",
      "Processing: Benefit_Options.pdf\n",
      "Processing: employee_handbook.pdf\n",
      "\n",
      "Total chunks to index: 55\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text content from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 2000, overlap: int = 500) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks.\n",
    "    \n",
    "    Default settings match the Azure AI Search portal wizard:\n",
    "    - maximumPageLength: 2000 characters\n",
    "    - pageOverlapLength: 500 characters\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        if chunk.strip():  # Only add non-empty chunks\n",
    "            chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Load documents from data/index1/\n",
    "data_path = Path(\"data/index2\")\n",
    "documents = []\n",
    "\n",
    "for pdf_file in data_path.glob(\"*.pdf\"):\n",
    "    print(f\"Processing: {pdf_file.name}\")\n",
    "    text = extract_text_from_pdf(str(pdf_file))\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    # parent_id is the hash of the source document (for grouping chunks)\n",
    "    parent_id = hashlib.md5(pdf_file.name.encode()).hexdigest()\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # chunk_id uniquely identifies each chunk (matches portal wizard format)\n",
    "        chunk_id = hashlib.md5(f\"{pdf_file.name}_{i}\".encode()).hexdigest()\n",
    "        documents.append({\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"parent_id\": parent_id,\n",
    "            \"chunk\": chunk,\n",
    "            \"title\": pdf_file.name,\n",
    "        })\n",
    "\n",
    "print(f\"\\nTotal chunks to index: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-5",
   "metadata": {},
   "source": [
    "### Step 1.5: Generate Embeddings\n",
    "\n",
    "We'll use Azure OpenAI to generate vector embeddings for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "generate-embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n",
      "  Processed 10/55 chunks\n",
      "  Processed 20/55 chunks\n",
      "  Processed 30/55 chunks\n",
      "  Processed 40/55 chunks\n",
      "  Processed 50/55 chunks\n",
      "âœ… Embeddings generated for 55 chunks\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Setup Azure OpenAI client for embeddings (using API key like other notebooks)\n",
    "openai_client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    \"\"\"Generate embedding for a text chunk.\"\"\"\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=embedding_deployment\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "# Generate embeddings for all chunks (this may take a few minutes)\n",
    "print(\"Generating embeddings...\")\n",
    "for i, doc in enumerate(documents):\n",
    "    doc[\"text_vector\"] = get_embedding(doc[\"chunk\"])  # Field name matches portal wizard\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(documents)} chunks\")\n",
    "\n",
    "print(f\"âœ… Embeddings generated for {len(documents)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-6",
   "metadata": {},
   "source": [
    "### Step 1.6: Upload Documents to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "upload-documents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1: 55/55 succeeded\n",
      "\n",
      "âœ… Document upload complete!\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Upload documents to the index\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_key)\n",
    ")\n",
    "\n",
    "# Upload in batches (Azure Search has a limit of 1000 documents per batch)\n",
    "batch_size = 100\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = documents[i:i + batch_size]\n",
    "    result = search_client.upload_documents(documents=batch)\n",
    "    succeeded = sum(1 for r in result if r.succeeded)\n",
    "    print(f\"Uploaded batch {i // batch_size + 1}: {succeeded}/{len(batch)} succeeded\")\n",
    "\n",
    "print(f\"\\nâœ… Document upload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Understanding RAG\n",
    "\n",
    "### What is Retrieval-Augmented Generation?\n",
    "\n",
    "**RAG** is a pattern that enhances LLM responses by retrieving relevant information from external knowledge sources before generating an answer.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        RAG Architecture                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   User Query â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚\n",
    "â”‚                    â”‚                                            â”‚\n",
    "â”‚                    â–¼                                            â”‚\n",
    "â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚\n",
    "â”‚         â”‚   Azure AI Search   â”‚  â—„â”€â”€ Vectorized Documents       â”‚\n",
    "â”‚         â”‚   (Retrieval)       â”‚                                 â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚\n",
    "â”‚                   â”‚                                             â”‚\n",
    "â”‚                   â”‚ Retrieved Context                           â”‚\n",
    "â”‚                   â–¼                                             â”‚\n",
    "â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚\n",
    "â”‚         â”‚   LLM (Generation)  â”‚  â—„â”€â”€ Query + Context            â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚\n",
    "â”‚                   â”‚                                             â”‚\n",
    "â”‚                   â–¼                                             â”‚\n",
    "â”‚            Grounded Response                                    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Why RAG?\n",
    "\n",
    "| Problem | How RAG Solves It |\n",
    "|---------|-------------------|\n",
    "| **Hallucination** | Grounds responses in retrieved facts |\n",
    "| **Stale Knowledge** | Retrieves from up-to-date indexes |\n",
    "| **Context Limits** | Only retrieves relevant chunks, not entire documents |\n",
    "| **Data Privacy** | Keeps proprietary data in your own indexes |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Manual RAG - Feel the Pain\n",
    "\n",
    "Before using abstractions, let's understand what's happening under the hood. We'll build a RAG system step-by-step:\n",
    "\n",
    "1. Connect to Azure AI Search\n",
    "2. Create a search function\n",
    "3. Manually inject retrieved context into the prompt\n",
    "4. Generate a response\n",
    "\n",
    "This \"raw\" approach gives you full control and helps you understand the mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-1",
   "metadata": {},
   "source": [
    "### Step 3.1: Perform a Raw Search\n",
    "\n",
    "Let's see what the search returns **before** we add any LLM processing. This is the \"Retrieval\" part of RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "raw-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Northwind_Health_Plus_Benefits_Details.pdf (score: 0.025)\n",
      "   . This will help ensure that your transportation request is processed in \n",
      "time for your appointment. Additionally, be sure to have your Northwind Health Plus \n",
      "member ID card with you when you receive ...\n",
      "\n",
      "ðŸ“„ Northwind_Health_Plus_Benefits_Details.pdf (score: 0.024)\n",
      "   orthwind Health Plus offers a \n",
      "network of providers that are in-network, including primary care physicians, specialists, \n",
      "hospitals, and pharmacies.  \n",
      "Out-of-Network Services \n",
      "In some cases, it may be...\n",
      "\n",
      "ðŸ“„ Northwind_Health_Plus_Benefits_Details.pdf (score: 0.024)\n",
      "   nity and newborn care, preventive and \n",
      "wellness services, mental health and substance abuse services, and prescription drugs. The \n",
      "plan also must provide coverage for preventive services without cost ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "\n",
    "def search_documents(query: str, top_k: int = 3) -> list[dict]:\n",
    "    \"\"\"Search the index using hybrid search (text + vector).\"\"\"\n",
    "    # Generate embedding for the query\n",
    "    query_vector = get_embedding(query)\n",
    "    \n",
    "    # Create vector query targeting the text_vector field (matches portal wizard)\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        k=top_k,\n",
    "        fields=\"text_vector\"  # Field name matches portal wizard schema\n",
    "    )\n",
    "    \n",
    "    # Perform hybrid search\n",
    "    results = search_client.search(\n",
    "        search_text=query,  # Text search on 'chunk' field\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"chunk_id\", \"parent_id\", \"chunk\", \"title\"],\n",
    "        top=top_k\n",
    "    )\n",
    "    \n",
    "    return [{\n",
    "        \"chunk_id\": r[\"chunk_id\"],\n",
    "        \"title\": r[\"title\"],\n",
    "        \"chunk\": r[\"chunk\"][:200] + \"...\",\n",
    "        \"score\": r[\"@search.score\"]\n",
    "    } for r in results]\n",
    "\n",
    "\n",
    "# Test the search\n",
    "test_results = search_documents(\"What mental health services are covered?\")\n",
    "for r in test_results:\n",
    "    print(f\"ðŸ“„ {r['title']} (score: {r['score']:.3f})\")\n",
    "    print(f\"   {r['chunk']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-2",
   "metadata": {},
   "source": [
    "### Step 3.2: Manual RAG - Injecting Context into the Prompt\n",
    "\n",
    "Now let's manually construct a prompt that includes the retrieved context. This is the core RAG pattern - **retrieve, then generate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "manual-rag",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the deductible for Northwind Health Plus?\n",
      "\n",
      "Answer: The Northwind Health Plus plan has a calendar year deductible that applies to some services. However, I don't have the specific deductible amount.\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Create chat client using API key (same pattern as other notebooks)\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    endpoint=openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=api_version,\n",
    "    deployment_name=chat_deployment,\n",
    ")\n",
    "\n",
    "\n",
    "async def manual_rag(user_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform RAG manually:\n",
    "    1. Search for relevant documents\n",
    "    2. Build a prompt with the context\n",
    "    3. Generate a response\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant context\n",
    "    retrieved_docs = search_documents(user_question, top_k=3)\n",
    "    \n",
    "    # Step 2: Format context for the prompt\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"[Source: {doc['title']}]\\n{doc['chunk']}\" \n",
    "        for doc in retrieved_docs\n",
    "    ])\n",
    "    \n",
    "    # Step 3: Build the augmented prompt\n",
    "    system_prompt = f\"\"\"You are an HR assistant for Contoso Electronics.\n",
    "Answer questions based ONLY on the following retrieved context.\n",
    "If the context doesn't contain the answer, say \"I don't have that information.\"\n",
    "\n",
    "## Retrieved Context:\n",
    "{context_text}\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 4: Generate response using the agent\n",
    "    agent = chat_client.as_agent(\n",
    "        name=\"manual_rag_agent\",\n",
    "        instructions=system_prompt\n",
    "    )\n",
    "    \n",
    "    response = await agent.run(user_question)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Test manual RAG\n",
    "question = \"What is the deductible for Northwind Health Plus?\"\n",
    "answer = await manual_rag(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-rag-problems",
   "metadata": {},
   "source": [
    "### The Problems with Manual RAG\n",
    "\n",
    "While this works, there are several issues:\n",
    "\n",
    "| Problem | Description |\n",
    "|---------|-------------|\n",
    "| **Boilerplate Code** | You must write retrieval logic for every agent |\n",
    "| **No Multi-turn Memory** | Context isn't automatically managed across conversation turns |\n",
    "| **Token Management** | You must manually handle context window limits |\n",
    "| **Multiple Sources** | Combining multiple indexes requires custom orchestration |\n",
    "| **Serialization** | Persisting conversation state requires custom code |\n",
    "\n",
    "In the next section, we'll see how Function Tools can improve this, and in the next notebook, how **Context Providers** solve all these problems elegantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Function Tools for Search\n",
    "\n",
    "An intermediate approach is to wrap the search as a **function tool** that the agent can call. This gives the agent **agency** - it decides when to search, rather than searching on every query.\n",
    "\n",
    "### When to Use Tools vs. Context Providers\n",
    "\n",
    "| Approach | Use When |\n",
    "|----------|----------|\n",
    "| **Function Tool** | Agent should decide when to search (optional retrieval) |\n",
    "| **Context Provider** | Every query needs grounding (automatic retrieval) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "search-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import json\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "\n",
    "class AzureAISearchTool:\n",
    "    \"\"\"\n",
    "    A function tool that wraps Azure AI Search for use by an agent.\n",
    "    \n",
    "    The agent decides when to call this tool based on the user's question.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, search_client: SearchClient, index_name: str):\n",
    "        self.search_client = search_client\n",
    "        self.index_name = index_name\n",
    "    \n",
    "    def search(\n",
    "        self, \n",
    "        query: Annotated[str, \"The search query to find relevant documents\"],\n",
    "        top: Annotated[int, \"Number of results to return\"] = 5\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Search the Contoso HR knowledge base for information about health plans,\n",
    "        policies, and employee benefits.\n",
    "        \n",
    "        Use this tool to find:\n",
    "        - Health plan details (Northwind Health Plus, Northwind Standard)\n",
    "        - Coverage information, deductibles, and copays\n",
    "        - Eligibility requirements and enrollment procedures\n",
    "        - Company HR policies and benefits\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.search_client.search(\n",
    "                search_text=query,\n",
    "                top=top,\n",
    "                query_type=\"semantic\",\n",
    "                semantic_configuration_name=f\"{self.index_name}-semantic-configuration\",\n",
    "            )\n",
    "            \n",
    "            docs = []\n",
    "            for doc in results:\n",
    "                docs.append({\n",
    "                    \"content\": doc.get(\"chunk\", \"\"),\n",
    "                    \"score\": doc.get(\"@search.score\", 0),\n",
    "                    \"source\": doc.get(\"title\", \"Unknown\"),\n",
    "                })\n",
    "            \n",
    "            return json.dumps(docs, indent=2)\n",
    "            \n",
    "        except HttpResponseError as e:\n",
    "            return json.dumps({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tool-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is what I found about out-of-network copays for each health plan:\n",
      "\n",
      "**Northwind Health Plus:**\n",
      "- Out-of-network copays are typically higher than for in-network services.\n",
      "- The actual copay amount for out-of-network primary care visits is not specified, but documentation states they are \"higher than for in-network services.\"\n",
      "- For out-of-network providers, you may sometimes be responsible for the entire cost of care, unless exceptions apply (such as certain emergency or international situations).\n",
      "- You will also pay a deductible ($2,000/year) and 20% coinsurance for network services, but out-of-network coinsurance and copays are generally higher.\n",
      "(Source: Northwind Health Plus Benefits Details)\n",
      "\n",
      "**Northwind Standard:**\n",
      "- Out-of-network costs are significantly higher than in-network.\n",
      "- For out-of-network services, coinsurance is typically 40%.\n",
      "- Copays for out-of-network services are not specified, but you may need to pay the full cost or a far greater portion than in-network.\n",
      "- Primary care copay for in-network is $30, specialist is $50â€”for out-of-network, expect to pay much more, either via higher coinsurance or full price.\n",
      "(Source: Northwind Standard Benefits Details)\n",
      "\n",
      "If you need the exact dollar amounts for a specific service out-of-network, please let me know which type of visit or service you're asking about. Neither plan provides a detailed copay list for out-of-network servicesâ€”most out-of-network charges are either higher copays, coinsurance, or full charges.\n"
     ]
    }
   ],
   "source": [
    "# Create the search tool\n",
    "search_tool = AzureAISearchTool(search_client=search_client, index_name=index_name)\n",
    "\n",
    "# Create an agent with the search tool\n",
    "tool_agent = chat_client.as_agent(\n",
    "    name=\"hr_assistant\",\n",
    "    instructions=\"\"\"\n",
    "    You are an HR Assistant for Contoso Electronics specializing in employee health plans.\n",
    "    \n",
    "    IMPORTANT RULES:\n",
    "    1. ALWAYS use the search tool before answering questions about health plans\n",
    "    2. Base your responses ONLY on information from the search results\n",
    "    3. If the search returns no relevant information, say so explicitly\n",
    "    4. Cite which plan (Northwind Health Plus or Standard) the information comes from\n",
    "    \"\"\",\n",
    "    tools=[search_tool.search]\n",
    ")\n",
    "\n",
    "# Test the tool-based agent\n",
    "response = await tool_agent.run(\"What are the out-of-network copays?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tool-agent-test2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the search results, here is a comparison of deductibles for both plans:\n",
      "\n",
      "- **Northwind Health Plus**:\n",
      "  - The calendar year deductible for in-network services is $1,500 for individuals and $3,000 for families. (Northwind Health Plus)\n",
      "  - Certain services, such as preventive care and emergency services, are exempt from the deductible.\n",
      "\n",
      "- **Northwind Standard**:\n",
      "  - The calendar year deductible is $2,000 per person and $4,000 for each family. (Northwind Standard)\n",
      "  - Preventive care services are covered at 100% with no deductible.\n",
      "  - Prescription drugs have a separate deductible of $250 per individual and $500 per family.\n",
      "\n",
      "**Summary**: Northwind Health Plus has a lower deductible for both individuals and families compared to Northwind Standard. Additionally, both plans waive the deductible for preventive care, but Northwind Standard also has a separate prescription drug deductible.\n",
      "\n",
      "If you need further details on coinsurance or copays, let me know!\n"
     ]
    }
   ],
   "source": [
    "# Test with a question that spans multiple topics\n",
    "response = await tool_agent.run(\n",
    "    \"Compare the deductibles between Northwind Health Plus and Northwind Standard\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Improve the Search Tool\n",
    "\n",
    "The current search tool returns raw JSON. Improve it by:\n",
    "\n",
    "1. Formatting the results in a more readable way\n",
    "2. Adding error handling for empty results\n",
    "3. Limiting the content length per result to avoid token limits\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "def search(\n",
    "    self, \n",
    "    query: Annotated[str, \"The search query\"],\n",
    "    top: Annotated[int, \"Number of results\"] = 3\n",
    ") -> str:\n",
    "    \"\"\"Search the knowledge base.\"\"\"\n",
    "    try:\n",
    "        results = self.search_client.search(\n",
    "            search_text=query,\n",
    "            top=top,\n",
    "            query_type=\"semantic\"\n",
    "        )\n",
    "        \n",
    "        documents = list(results)\n",
    "        \n",
    "        if not documents:\n",
    "            return \"No relevant documents found for this query.\"\n",
    "        \n",
    "        # Format results with truncated content\n",
    "        formatted = []\n",
    "        for i, doc in enumerate(documents, 1):\n",
    "            content = doc.get(\"chunk\", \"\")[:500]  # Limit to 500 chars\n",
    "            source = doc.get(\"title\", \"Unknown\")\n",
    "            formatted.append(f\"[{i}] {source}\\n{content}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted)\n",
    "        \n",
    "    except HttpResponseError as e:\n",
    "        return f\"Search error: {str(e)}\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Programmatic Indexing** - How to create Azure AI Search indexes using Python code\n",
    "2. **RAG Mechanics** - The retrieve-then-generate pattern and why it matters\n",
    "3. **Manual RAG** - Building RAG from scratch to understand the complexity\n",
    "4. **Function Tools** - Giving agents the ability to search when needed\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Manual RAG works but requires significant boilerplate code\n",
    "- Function tools give agents control over when to search\n",
    "- Both approaches have limitations around multi-turn conversations and state management\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **03.2 - Context Providers**, you'll learn how the Agent Framework's Context Provider abstraction solves all these problems elegantly:\n",
    "\n",
    "- Automatic context injection on every invocation\n",
    "- Built-in multi-turn conversation support\n",
    "- Easy combination of multiple knowledge sources\n",
    "- Clean, declarative configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

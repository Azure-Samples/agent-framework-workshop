{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d",
   "metadata": {},
   "source": [
    "# Chapter 3: RAG Agents with Azure AI Search\n",
    "\n",
    "In this chapter, you'll learn how to build **Retrieval-Augmented Generation (RAG)** agents that ground their responses in your enterprise knowledge. We'll start from first principles, building a RAG system manually, and then show how the Agent Framework's **Context Providers** abstract away the complexity.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will:\n",
    "\n",
    "1. Understand the RAG pattern and why it's essential for enterprise AI\n",
    "2. Build a \"raw\" RAG implementation manually using Azure AI Search\n",
    "3. Refactor to use Context Providers as an abstraction layer\n",
    "4. Combine multiple knowledge sources with automatic context injection\n",
    "5. (Optional) Create search indexes programmatically using Python\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this notebook, complete the setup guide: `03.0-setup-guide.md`\n",
    "\n",
    "You should have:\n",
    "- An Azure AI Search service with at least one index created\n",
    "- The health plan documents indexed and vectorized\n",
    "- Environment variables configured in your `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup & Validation\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from workshop_utils import validate_env\n",
    "validate_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding RAG\n",
    "\n",
    "### What is Retrieval-Augmented Generation?\n",
    "\n",
    "**RAG** is a pattern that enhances LLM responses by retrieving relevant information from external knowledge sources before generating an answer.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                        RAG Architecture                         │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│   User Query ──────┬──────────────────────────────────────────► │\n",
    "│                    │                                            │\n",
    "│                    ▼                                            │\n",
    "│         ┌─────────────────────┐                                 │\n",
    "│         │   Azure AI Search   │  ◄── Vectorized Documents       │\n",
    "│         │   (Retrieval)       │                                 │\n",
    "│         └─────────┬───────────┘                                 │\n",
    "│                   │                                             │\n",
    "│                   │ Retrieved Context                           │\n",
    "│                   ▼                                             │\n",
    "│         ┌─────────────────────┐                                 │\n",
    "│         │   LLM (Generation)  │  ◄── Query + Context            │\n",
    "│         └─────────┬───────────┘                                 │\n",
    "│                   │                                             │\n",
    "│                   ▼                                             │\n",
    "│            Grounded Response                                    │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Why RAG?\n",
    "\n",
    "| Problem | How RAG Solves It |\n",
    "|---------|-------------------|\n",
    "| **Hallucination** | Grounds responses in retrieved facts |\n",
    "| **Stale Knowledge** | Retrieves from up-to-date indexes |\n",
    "| **Context Limits** | Only retrieves relevant chunks, not entire documents |\n",
    "| **Data Privacy** | Keeps proprietary data in your own indexes |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building RAG from Scratch (The Manual Way)\n",
    "\n",
    "Before using abstractions, let's understand what's happening under the hood. We'll build a RAG system step-by-step:\n",
    "\n",
    "1. Connect to Azure AI Search\n",
    "2. Create a search function\n",
    "3. Manually inject retrieved context into the prompt\n",
    "4. Generate a response\n",
    "\n",
    "This \"raw\" approach gives you full control and helps you understand the mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-connect",
   "metadata": {},
   "source": [
    "### Step 1: Load Environment Variables\n",
    "\n",
    "First, let's load our configuration. Make sure your `.env` file contains:\n",
    "\n",
    "```\n",
    "AZURE_SEARCH_ENDPOINT=https://<search-service-name>.search.windows.net\n",
    "INDEX_NAME=<your-index-name>\n",
    "SEARCH_API_KEY=<your-search-api-key>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search configuration\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"INDEX_NAME\")\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_AI_API_VERSION\")\n",
    "\n",
    "print(f\"Search Endpoint: {search_endpoint}\")\n",
    "print(f\"Index Name: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-search",
   "metadata": {},
   "source": [
    "### Step 2: Create the Search Client\n",
    "\n",
    "We'll use the Azure AI Search SDK to connect to our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-search-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Create the search client\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_key)\n",
    ")\n",
    "\n",
    "print(f\"Connected to index: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-raw-search",
   "metadata": {},
   "source": [
    "### Step 3: Perform a Raw Search\n",
    "\n",
    "Let's see what the search returns **before** we add any LLM processing. This is the \"Retrieval\" part of RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raw-search-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_knowledge_base(query: str, top_k: int = 3) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Search the Azure AI Search index and return relevant document chunks.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        top_k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of document chunks with content and scores\n",
    "    \"\"\"\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        top=top_k,\n",
    "        query_type=\"semantic\"  # Uses semantic ranking for better relevance\n",
    "    )\n",
    "    \n",
    "    documents = []\n",
    "    for doc in results:\n",
    "        documents.append({\n",
    "            \"content\": doc.get(\"chunk\", \"\"),\n",
    "            \"score\": doc.get(\"@search.score\", 0),\n",
    "            \"title\": doc.get(\"title\", \"Unknown\")\n",
    "        })\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Test the search\n",
    "test_query = \"What is the deductible for Northwind Health Plus?\"\n",
    "results = search_knowledge_base(test_query)\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(f\"Found {len(results)} relevant chunks:\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"--- Result {i} (score: {doc['score']:.2f}) ---\")\n",
    "    print(f\"Source: {doc['title']}\")\n",
    "    print(f\"Content: {doc['content'][:300]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-manual-rag",
   "metadata": {},
   "source": [
    "### Step 4: Manual RAG - Injecting Context into the Prompt\n",
    "\n",
    "Now let's manually construct a prompt that includes the retrieved context. This is the core RAG pattern - **retrieve, then generate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-rag",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity.aio import DefaultAzureCredential, get_bearer_token_provider\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Setup Azure OpenAI client\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential,\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=project_endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")\n",
    "\n",
    "\n",
    "async def manual_rag(user_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform RAG manually:\n",
    "    1. Search for relevant documents\n",
    "    2. Build a prompt with the context\n",
    "    3. Generate a response\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant context\n",
    "    retrieved_docs = search_knowledge_base(user_question, top_k=3)\n",
    "    \n",
    "    # Step 2: Format context for the prompt\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"[Source: {doc['title']}]\\n{doc['content']}\" \n",
    "        for doc in retrieved_docs\n",
    "    ])\n",
    "    \n",
    "    # Step 3: Build the augmented prompt\n",
    "    system_prompt = f\"\"\"You are an HR assistant for Contoso Electronics.\n",
    "Answer questions based ONLY on the following retrieved context.\n",
    "If the context doesn't contain the answer, say \"I don't have that information.\"\n",
    "\n",
    "## Retrieved Context:\n",
    "{context_text}\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 4: Generate response using the agent\n",
    "    agent = chat_client.as_agent(\n",
    "        name=\"manual_rag_agent\",\n",
    "        instructions=system_prompt\n",
    "    )\n",
    "    \n",
    "    response = await agent.run(user_question)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Test manual RAG\n",
    "question = \"What is the deductible for Northwind Health Plus?\"\n",
    "answer = await manual_rag(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-rag-problems",
   "metadata": {},
   "source": [
    "### The Problems with Manual RAG\n",
    "\n",
    "While this works, there are several issues:\n",
    "\n",
    "| Problem | Description |\n",
    "|---------|-------------|\n",
    "| **Boilerplate Code** | You must write retrieval logic for every agent |\n",
    "| **No Multi-turn Memory** | Context isn't automatically managed across conversation turns |\n",
    "| **Token Management** | You must manually handle context window limits |\n",
    "| **Multiple Sources** | Combining multiple indexes requires custom orchestration |\n",
    "| **Serialization** | Persisting conversation state requires custom code |\n",
    "\n",
    "This is where **Context Providers** come in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Using Function Tools (Intermediate Approach)\n",
    "\n",
    "Before jumping to Context Providers, let's look at an intermediate approach: wrapping the search as a **function tool** that the agent can call.\n",
    "\n",
    "This gives the agent **agency** - it decides when to search, rather than searching on every query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "search-tool-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "\n",
    "class AzureAISearchTool:\n",
    "    \"\"\"\n",
    "    A function tool that wraps Azure AI Search for use by an agent.\n",
    "    \n",
    "    The agent decides when to call this tool based on the user's question.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, search_client: SearchClient):\n",
    "        self.search_client = search_client\n",
    "    \n",
    "    def search(\n",
    "        self, \n",
    "        query: Annotated[str, \"The search query to find relevant documents\"],\n",
    "        top: Annotated[int, \"Number of results to return\"] = 5\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Search the Contoso HR knowledge base for information about health plans,\n",
    "        policies, and employee benefits.\n",
    "        \n",
    "        Use this tool to find:\n",
    "        - Health plan details (Northwind Health Plus, Northwind Standard)\n",
    "        - Coverage information, deductibles, and copays\n",
    "        - Eligibility requirements and enrollment procedures\n",
    "        - Company HR policies and benefits\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.search_client.search(\n",
    "                search_text=query,\n",
    "                top=top,\n",
    "                query_type=\"semantic\"\n",
    "            )\n",
    "            \n",
    "            documents = []\n",
    "            for doc in results:\n",
    "                documents.append({\n",
    "                    \"chunk\": doc.get(\"chunk\", \"\"),\n",
    "                    \"score\": doc.get(\"@search.score\", 0)\n",
    "                })\n",
    "            \n",
    "            return json.dumps(documents, indent=2)\n",
    "            \n",
    "        except HttpResponseError as e:\n",
    "            return json.dumps({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-based-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search tool\n",
    "search_tool = AzureAISearchTool(search_client=search_client)\n",
    "\n",
    "# Create an agent with the search tool\n",
    "tool_agent = chat_client.as_agent(\n",
    "    name=\"hr_assistant\",\n",
    "    instructions=\"\"\"\n",
    "    You are an HR Assistant for Contoso Electronics specializing in employee health plans.\n",
    "    \n",
    "    IMPORTANT RULES:\n",
    "    1. ALWAYS use the search tool before answering questions about health plans\n",
    "    2. Base your responses ONLY on information from the search results\n",
    "    3. If the search returns no relevant information, say so explicitly\n",
    "    4. Cite which plan (Northwind Health Plus or Standard) the information comes from\n",
    "    \"\"\",\n",
    "    tools=[search_tool.search]\n",
    ")\n",
    "\n",
    "# Test the tool-based agent\n",
    "response = await tool_agent.run(\"What are the out-of-network copays?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tool-vs-context",
   "metadata": {},
   "source": [
    "### Tools vs. Context Providers: When to Use Which?\n",
    "\n",
    "| Approach | Use When |\n",
    "|----------|----------|\n",
    "| **Function Tool** | Agent should decide when to search (optional retrieval) |\n",
    "| **Context Provider** | Every query needs grounding (automatic retrieval) |\n",
    "\n",
    "For RAG scenarios where you always want to ground the agent's responses, **Context Providers** are the better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Context Providers - The Abstraction Layer\n",
    "\n",
    "**Context Providers** are middleware components in the Agent Framework that run before and after every agent invocation. They solve all the problems we identified with manual RAG:\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    Context Provider Pipeline                       │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│  User Message ──► invoking() ──► Agent ──► invoked() ──► Response │\n",
    "│                      │                         │                   │\n",
    "│                      │                         │                   │\n",
    "│                      ▼                         ▼                   │\n",
    "│              Inject Context             Extract Memories           │\n",
    "│              (from search)              (for future use)           │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Methods\n",
    "\n",
    "| Method | When It Runs | Purpose |\n",
    "|--------|--------------|----------|\n",
    "| `invoking()` | Before LLM call | Inject retrieved context, instructions, or tools |\n",
    "| `invoked()` | After LLM call | Extract information, update memory, log interactions |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-search-provider",
   "metadata": {},
   "source": [
    "### AzureAISearchContextProvider\n",
    "\n",
    "The Agent Framework provides a built-in `AzureAISearchContextProvider` that automatically:\n",
    "\n",
    "1. Searches your index on every user message\n",
    "2. Injects relevant documents as context\n",
    "3. Handles authentication and connection management\n",
    "\n",
    "Here's how the same RAG pattern looks with Context Providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context-provider-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureAISearchContextProvider\n",
    "\n",
    "# Create the context provider - this replaces all our manual search code!\n",
    "search_provider = AzureAISearchContextProvider(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    mode=\"semantic\",  # Use semantic search for better relevance\n",
    "    top_k=3,          # Retrieve top 3 most relevant documents\n",
    ")\n",
    "\n",
    "# Create the agent with the context provider\n",
    "async with (\n",
    "    search_provider,\n",
    "    ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"HRAgent\",\n",
    "        instructions=\"\"\"\n",
    "        You are a helpful HR assistant for Contoso Electronics employees.\n",
    "        \n",
    "        Answer questions using ONLY the context provided to you.\n",
    "        If the context doesn't contain the answer, say \"I don't have that information.\"\n",
    "        Be concise and cite specific plan names when applicable.\n",
    "        \"\"\",\n",
    "        context_providers=[search_provider],\n",
    "    ) as agent,\n",
    "):\n",
    "    # The context provider automatically searches and injects context\n",
    "    response = await agent.run(\"What is the deductible for Northwind Health Plus?\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-table",
   "metadata": {},
   "source": [
    "### Compare: Manual RAG vs. Context Provider\n",
    "\n",
    "| Aspect | Manual RAG | Context Provider |\n",
    "|--------|------------|------------------|\n",
    "| **Code Lines** | ~30 lines per agent | ~5 lines configuration |\n",
    "| **Search Timing** | Manual before each call | Automatic on every invocation |\n",
    "| **Multi-turn** | Custom thread management | Built-in with `AgentThread` |\n",
    "| **Multiple Sources** | Custom orchestration | Just add more providers |\n",
    "| **Serialization** | Custom code | Built-in `serialize()` |\n",
    "| **Token Management** | Manual | Configurable `top_k` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Multiple Knowledge Sources\n",
    "\n",
    "A powerful feature of Context Providers is combining multiple knowledge sources. Each provider contributes context independently, and the agent receives a unified view.\n",
    "\n",
    "For this section, you'll need a second index. Follow Exercise 1 below to create it, or use the optional programmatic indexing in Part 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise1",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a Second Knowledge Base\n",
    "\n",
    "Create a second Azure AI Search index using the documents in `data/index2/` folder. This index contains general HR documents:\n",
    "\n",
    "- Employee benefits overview\n",
    "- Company policies and handbook\n",
    "- Wellness programs\n",
    "- Role descriptions\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Upload documents from `data/index2/` to a new container in your storage account\n",
    "2. Create a new index in Azure AI Search using the portal wizard\n",
    "3. Use the same vectorization settings as your first index\n",
    "4. Add the new index name to your `.env` file as `INDEX2_NAME`\n",
    "\n",
    "<details>\n",
    "<summary>Click to see detailed instructions</summary>\n",
    "\n",
    "**1. Create a new blob container:**\n",
    "- Go to your Storage Account in Azure Portal\n",
    "- Navigate to Data Storage > Containers\n",
    "- Click \"+ Container\" and name it `hr-general-docs`\n",
    "- Upload all files from `data/index2/`\n",
    "\n",
    "**2. Create the search index:**\n",
    "- Go to your Azure AI Search service\n",
    "- Click \"Import data (new)\"\n",
    "- Select Azure Blob Storage as the data source\n",
    "- Select the RAG scenario\n",
    "- Point to your new container\n",
    "- Use `text-embedding-3-large` for vectorization\n",
    "- Name the index (e.g., `hr-general-index`)\n",
    "\n",
    "**3. Update your `.env` file:**\n",
    "```\n",
    "INDEX2_NAME=hr-general-index\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi-source-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second index name\n",
    "load_dotenv(override=True)  # Reload to get new env vars\n",
    "index2_name = os.getenv(\"INDEX2_NAME\")\n",
    "\n",
    "if not index2_name:\n",
    "    print(\"INDEX2_NAME not found in .env - please complete Exercise 1 first\")\n",
    "else:\n",
    "    print(f\"Second index configured: {index2_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dual-provider-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two context providers - one for each knowledge base\n",
    "health_plans_provider = AzureAISearchContextProvider(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,  # Health plans index\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    mode=\"semantic\",\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "general_hr_provider = AzureAISearchContextProvider(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index2_name,  # General HR index\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    mode=\"semantic\",\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "# Test questions that span both knowledge bases\n",
    "TEST_QUESTIONS = [\n",
    "    \"What's ERISA?\",  # General HR knowledge\n",
    "    \"What does Northwind Standard not cover?\",  # Health plans\n",
    "    \"Can independent contractor services be covered?\",  # Health plans\n",
    "    \"What does the VP of Sales do?\",  # General HR (role descriptions)\n",
    "    \"What are out-of-network copays?\",  # Health plans\n",
    "]\n",
    "\n",
    "async with (\n",
    "    health_plans_provider,\n",
    "    general_hr_provider,\n",
    "    ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"ComprehensiveHRAgent\",\n",
    "        instructions=\"\"\"\n",
    "        You are a helpful HR assistant for Contoso Electronics employees.\n",
    "\n",
    "        You have access to two knowledge bases:\n",
    "        1. **Health Plan Details**: Northwind Health Plus and Standard plan specifics\n",
    "        2. **General HR Knowledge**: Company policies, benefits overview, role descriptions\n",
    "\n",
    "        Guidelines:\n",
    "        - Answer using ONLY the context provided\n",
    "        - Keep responses to 2-3 sentences\n",
    "        - Cite specific plan names when discussing health coverage\n",
    "        - If information isn't available, say so clearly\n",
    "        \"\"\",\n",
    "        context_providers=[health_plans_provider, general_hr_provider],\n",
    "    ) as hr_agent,\n",
    "):\n",
    "    for question in TEST_QUESTIONS:\n",
    "        print(f\"User: {question}\")\n",
    "        print(\"Agent: \", end=\"\", flush=True)\n",
    "        \n",
    "        async for chunk in hr_agent.run_stream(question):\n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Programmatic Index Creation (Optional)\n",
    "\n",
    "While the Azure Portal wizard is convenient, you may need to create indexes programmatically for:\n",
    "\n",
    "- CI/CD pipelines\n",
    "- Dynamic index creation\n",
    "- Infrastructure as Code\n",
    "- Testing environments\n",
    "\n",
    "The Azure AI Search SDK for Python supports full index lifecycle management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "programmatic-indexing-intro",
   "metadata": {},
   "source": [
    "### Creating an Index Programmatically\n",
    "\n",
    "Here's how to create a vector search index from scratch using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "programmatic-index-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    ")\n",
    "\n",
    "\n",
    "def create_vector_index(\n",
    "    index_client: SearchIndexClient,\n",
    "    index_name: str,\n",
    "    vector_dimensions: int = 3072  # text-embedding-3-large dimensions\n",
    ") -> SearchIndex:\n",
    "    \"\"\"\n",
    "    Create a vector search index programmatically.\n",
    "    \n",
    "    Args:\n",
    "        index_client: The SearchIndexClient\n",
    "        index_name: Name for the new index\n",
    "        vector_dimensions: Dimensions of your embedding model\n",
    "        \n",
    "    Returns:\n",
    "        The created SearchIndex\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the fields\n",
    "    fields = [\n",
    "        # Document key - required\n",
    "        SearchField(\n",
    "            name=\"chunk_id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=True,\n",
    "            sortable=True,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        # Parent document reference\n",
    "        SearchField(\n",
    "            name=\"parent_id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        # The actual text content\n",
    "        SearchField(\n",
    "            name=\"chunk\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "        ),\n",
    "        # Document title/source\n",
    "        SearchField(\n",
    "            name=\"title\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "            filterable=True,\n",
    "        ),\n",
    "        # Vector field for semantic search\n",
    "        SearchField(\n",
    "            name=\"text_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=vector_dimensions,\n",
    "            vector_search_profile_name=\"default-vector-profile\",\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # Configure vector search\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(name=\"default-hnsw\"),\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"default-vector-profile\",\n",
    "                algorithm_configuration_name=\"default-hnsw\",\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # Configure semantic search\n",
    "    semantic_config = SemanticConfiguration(\n",
    "        name=\"default-semantic-config\",\n",
    "        prioritized_fields=SemanticPrioritizedFields(\n",
    "            content_fields=[SemanticField(field_name=\"chunk\")],\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    semantic_search = SemanticSearch(\n",
    "        configurations=[semantic_config],\n",
    "        default_configuration_name=\"default-semantic-config\",\n",
    "    )\n",
    "    \n",
    "    # Create the index\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "        semantic_search=semantic_search,\n",
    "    )\n",
    "    \n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f\"Created index: {result.name}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "# index_client = SearchIndexClient(\n",
    "#     endpoint=search_endpoint,\n",
    "#     credential=AzureKeyCredential(search_key)\n",
    "# )\n",
    "# \n",
    "# create_vector_index(index_client, \"my-programmatic-index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload-documents",
   "metadata": {},
   "source": [
    "### Uploading Documents with Embeddings\n",
    "\n",
    "After creating the index, you need to upload documents with their vector embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-docs-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "\n",
    "def get_embedding(text: str, embedding_client: AzureOpenAI, model: str) -> list[float]:\n",
    "    \"\"\"\n",
    "    Generate an embedding vector for the given text.\n",
    "    \"\"\"\n",
    "    response = embedding_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "def upload_documents_with_embeddings(\n",
    "    search_client: SearchClient,\n",
    "    documents: list[dict],\n",
    "    embedding_client: AzureOpenAI,\n",
    "    embedding_model: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload documents to the search index with generated embeddings.\n",
    "    \n",
    "    Args:\n",
    "        search_client: The SearchClient for the target index\n",
    "        documents: List of dicts with 'chunk_id', 'chunk', 'title', 'parent_id'\n",
    "        embedding_client: AzureOpenAI client for embeddings\n",
    "        embedding_model: Name of the embedding model deployment\n",
    "    \"\"\"\n",
    "    docs_to_upload = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Generate embedding for the chunk\n",
    "        embedding = get_embedding(doc[\"chunk\"], embedding_client, embedding_model)\n",
    "        \n",
    "        docs_to_upload.append({\n",
    "            \"chunk_id\": doc[\"chunk_id\"],\n",
    "            \"parent_id\": doc.get(\"parent_id\", \"\"),\n",
    "            \"chunk\": doc[\"chunk\"],\n",
    "            \"title\": doc.get(\"title\", \"\"),\n",
    "            \"text_vector\": embedding,\n",
    "        })\n",
    "    \n",
    "    # Upload in batches\n",
    "    result = search_client.upload_documents(documents=docs_to_upload)\n",
    "    print(f\"Uploaded {len(docs_to_upload)} documents\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example: Processing PDF files\n",
    "def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# \n",
    "# # Setup embedding client\n",
    "# from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "# \n",
    "# sync_credential = DefaultAzureCredential()\n",
    "# sync_token_provider = get_bearer_token_provider(\n",
    "#     sync_credential, \"https://cognitiveservices.azure.com/.default\"\n",
    "# )\n",
    "# \n",
    "# embedding_client = AzureOpenAI(\n",
    "#     azure_endpoint=project_endpoint,\n",
    "#     azure_ad_token_provider=sync_token_provider,\n",
    "#     api_version=api_version\n",
    "# )\n",
    "# \n",
    "# # Prepare documents\n",
    "# sample_documents = [\n",
    "#     {\n",
    "#         \"chunk_id\": \"doc1-chunk1\",\n",
    "#         \"parent_id\": \"doc1\",\n",
    "#         \"chunk\": \"This is the first chunk of content...\",\n",
    "#         \"title\": \"Sample Document 1\"\n",
    "#     },\n",
    "#     # ... more documents\n",
    "# ]\n",
    "# \n",
    "# # Upload with embeddings\n",
    "# upload_search_client = SearchClient(\n",
    "#     endpoint=search_endpoint,\n",
    "#     index_name=\"my-programmatic-index\",\n",
    "#     credential=AzureKeyCredential(search_key)\n",
    "# )\n",
    "# \n",
    "# upload_documents_with_embeddings(\n",
    "#     upload_search_client,\n",
    "#     sample_documents,\n",
    "#     embedding_client,\n",
    "#     \"text-embedding-3-large\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "programmatic-summary",
   "metadata": {},
   "source": [
    "### Programmatic Indexing: Key Points\n",
    "\n",
    "| Step | What You Need |\n",
    "|------|---------------|\n",
    "| **1. Create Index** | `SearchIndexClient` with index schema definition |\n",
    "| **2. Generate Embeddings** | Azure OpenAI embedding model (e.g., `text-embedding-3-large`) |\n",
    "| **3. Upload Documents** | `SearchClient.upload_documents()` with vectors |\n",
    "| **4. Configure Semantic Search** | `SemanticConfiguration` with content/title fields |\n",
    "\n",
    "> **Note**: For production, consider using Azure AI Search's built-in indexers with skillsets, which handle chunking and embedding automatically. The programmatic approach shown here is useful for custom pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary & Key Concepts\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **RAG Pattern** | Retrieve relevant documents before generating responses to ground the LLM |\n",
    "| **Manual RAG** | Building retrieval + generation from scratch for full control |\n",
    "| **Function Tools** | Agent-controlled search (agent decides when to retrieve) |\n",
    "| **Context Providers** | Automatic context injection before every invocation |\n",
    "| **AzureAISearchContextProvider** | Built-in provider for Azure AI Search integration |\n",
    "| **Multiple Sources** | Combining multiple indexes with multiple providers |\n",
    "\n",
    "### Key Code Patterns\n",
    "\n",
    "**1. Creating a Context Provider:**\n",
    "```python\n",
    "from agent_framework.azure import AzureAISearchContextProvider\n",
    "\n",
    "provider = AzureAISearchContextProvider(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    mode=\"semantic\",\n",
    "    top_k=3,\n",
    ")\n",
    "```\n",
    "\n",
    "**2. Using Context Provider with ChatAgent:**\n",
    "```python\n",
    "async with (\n",
    "    provider,\n",
    "    ChatAgent(\n",
    "        chat_client=client,\n",
    "        instructions=\"Your instructions here\",\n",
    "        context_providers=[provider],\n",
    "    ) as agent,\n",
    "):\n",
    "    response = await agent.run(\"Your question\")\n",
    "```\n",
    "\n",
    "**3. Multiple Knowledge Sources:**\n",
    "```python\n",
    "context_providers=[provider1, provider2, provider3]\n",
    "```\n",
    "\n",
    "### Architecture Decision Guide\n",
    "\n",
    "| Scenario | Approach |\n",
    "|----------|----------|\n",
    "| Always need grounding | Context Provider (automatic) |\n",
    "| Sometimes need search | Function Tool (agent-controlled) |\n",
    "| Multiple knowledge bases | Multiple Context Providers |\n",
    "| Custom retrieval logic | Implement `ContextProvider` base class |\n",
    "| CI/CD index creation | Programmatic with `SearchIndexClient` |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other context providers: `Mem0Provider` for long-term memory, `RedisProvider` for state management\n",
    "- Check out [Azure AI Search Agentic Retrieval](https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-overview) for advanced multi-query RAG\n",
    "- Learn about thread serialization for persisting conversations with context\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Agent Framework Context Provider Samples](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/context_providers)\n",
    "- [Azure AI Search Documentation](https://learn.microsoft.com/en-us/azure/search/)\n",
    "- [Agent Framework Memory Tutorial](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

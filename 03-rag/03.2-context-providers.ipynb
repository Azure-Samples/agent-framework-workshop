{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Chapter 3.2: Context Providers\n",
    "\n",
    "> **Previously**: You built Ask HR manually and felt the pain of boilerplate code. Now let's see how Context Providers make this elegant.\n",
    "\n",
    "In this notebook, Ask HR finally gets easy. Context Providers automatically inject relevant documents into every request - no more manual search-and-stuff-the-prompt logic.\n",
    "\n",
    "**What you'll build:**\n",
    "1. Ask HR with automatic RAG (one config, zero boilerplate)\n",
    "2. Multi-source retrieval (combine multiple knowledge bases)\n",
    "3. Personalized responses (inject user profile, time, memory)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Complete `03.1-rag-fundamentals.ipynb` first (you need the search index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Azure SDK warning FIRST before any imports\n",
    "# (agent-framework uses k_nearest_neighbors but SDK expects k - harmless mismatch)\n",
    "import logging\n",
    "logging.getLogger(\"azure.search.documents\").setLevel(logging.ERROR)\n",
    "\n",
    "# Environment Setup & Validation\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from workshop_utils import validate_env\n",
    "validate_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search configuration\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"INDEX_NAME\")\n",
    "\n",
    "# Azure OpenAI configuration (same as other notebooks)\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Search Endpoint: {search_endpoint}\")\n",
    "print(f\"Index Name: {index_name}\")\n",
    "print(f\"OpenAI Endpoint: {openai_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding Context Providers\n",
    "\n",
    "Context Providers are middleware that run before and after every agent invocation. Let's see one in action first, then understand how it works.\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    Context Provider Pipeline                       │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│  User Message ──► invoking() ──► Agent ──► invoked() ──► Response │\n",
    "│                      │                         │                   │\n",
    "│                      ▼                         ▼                   │\n",
    "│              Inject Context             Extract/Store Info         │\n",
    "│              (from search)              (for future use)           │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Two methods, two purposes:\\n\n",
    "- **`invoking()`** runs before the LLM - use it to inject context, instructions, or tools\\n\n",
    "- **`invoked()`** runs after the LLM - use it to extract info, update memory, or log\\n\n",
    "\\n\n",
    "This solves everything we struggled with in 03.1: no more boilerplate, built-in multi-turn support, automatic token management, and easy multi-source aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: AzureAISearchContextProvider\n",
    "\n",
    "The Agent Framework provides a built-in `AzureAISearchContextProvider` that automatically:\n",
    "\n",
    "1. Searches your index on every user message\n",
    "2. Injects relevant documents as context\n",
    "3. Handles authentication and connection management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context-provider-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncAzureOpenAI\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAISearchContextProvider\n",
    "\n",
    "\n",
    "async def get_embedding(text: str) -> list[float]:\n",
    "    \"\"\"Generate embedding for search queries.\"\"\"\n",
    "    async with AsyncAzureOpenAI(\n",
    "        api_version=api_version,\n",
    "        azure_endpoint=openai_endpoint,\n",
    "        api_key=openai_api_key,\n",
    "    ) as client:\n",
    "        response = await client.embeddings.create(\n",
    "            input=text,\n",
    "            model=embedding_deployment\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "\n",
    "\n",
    "# Create chat client (AzureOpenAIChatClient doesn't require explicit cleanup)\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    endpoint=openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=api_version,\n",
    "    deployment_name=chat_deployment,\n",
    ")\n",
    "\n",
    "# Create the context provider with embedding function for vector search\n",
    "search_provider = AzureAISearchContextProvider(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    api_key=search_key,\n",
    "    mode=\"semantic\",\n",
    "    top_k=3,\n",
    "    semantic_configuration_name=f\"{index_name}-semantic-configuration\",\n",
    "    vector_field_name=\"text_vector\",\n",
    "    embedding_function=get_embedding,\n",
    ")\n",
    "\n",
    "async with (\n",
    "    search_provider,\n",
    "    ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"HRAgent\",\n",
    "        instructions=\"\"\"\n",
    "        You are a helpful HR assistant for Contoso Electronics employees.\n",
    "        \n",
    "        Answer questions using ONLY the context provided to you.\n",
    "        If the context doesn't contain the answer, say \"I don't have that information.\"\n",
    "        Be concise and cite specific plan names when applicable.\n",
    "        \"\"\",\n",
    "        context_provider=search_provider,\n",
    "    ) as agent,\n",
    "):\n",
    "    response = await agent.run(\"What is the deductible for Northwind Health Plus?\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-approaches",
   "metadata": {},
   "source": [
    "### Compare: Manual RAG vs. Context Provider\n",
    "\n",
    "Notice the difference? In 03.1, we wrote ~30 lines of search logic, prompt construction, and context injection for every query. Here, it's ~5 lines of configuration. The provider automatically searches on every message, handles multi-turn conversations with `AgentThread`, and serialization is built-in. That's the point of abstractions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-section",
   "metadata": {},
   "source": [
    "### Streaming Responses\n",
    "\n",
    "Context Providers work seamlessly with streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with (\n",
    "    search_provider,\n",
    "    ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"HRAgent\",\n",
    "        instructions=\"You are a helpful HR assistant. Answer based on provided context.\",\n",
    "        context_provider=search_provider,\n",
    "    ) as agent,\n",
    "):\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "    \n",
    "    async for chunk in agent.run_stream(\"What is covered under preventive care?\"):\n",
    "        if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi-turn-section",
   "metadata": {},
   "source": [
    "### Multi-turn Conversations with AgentThread\n",
    "\n",
    "Context Providers maintain state across conversation turns using `AgentThread`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi-turn-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with (\n",
    "    search_provider,\n",
    "    ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"HRAgent\",\n",
    "        instructions=\"You are a helpful HR assistant. Answer based on provided context. Be concise.\",\n",
    "        context_provider=search_provider,\n",
    "    ) as agent,\n",
    "):\n",
    "    # Create a conversation thread\n",
    "    thread = agent.get_new_thread()\n",
    "    \n",
    "    # Multi-turn conversation\n",
    "    questions = [\n",
    "        \"What is the deductible for Northwind Health Plus?\",\n",
    "        \"And what about the coinsurance?\",  # Follow-up referring to same plan\n",
    "        \"How does that compare to Northwind Standard?\",  # Comparison\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nUser: {question}\")\n",
    "        response = await agent.run(question, thread=thread)\n",
    "        print(f\"Agent: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Multiple Knowledge Sources with AggregateContextProvider\n",
    "\n",
    "> What if Ask HR needs to answer from multiple knowledge bases - health plans AND company policies?\n",
    "\n",
    "The `AggregateContextProvider` combines multiple providers by calling all of them in parallel and merging their results. Since `ChatAgent` accepts only one `context_provider`, we wrap multiple providers in an aggregate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise1",
   "metadata": {},
   "source": [
    "### Exercise 1: Build a Document Filter Provider\n",
    "\n",
    "The search provider returns results from all documents. What if you want Ask HR to ONLY answer from the employee handbook (ignoring health plan docs)?\n",
    "\n",
    "**Your task:** Create a `DocumentFilterContextProvider` that wraps a search provider and filters results by document title.\n",
    "\n",
    "```python\n",
    "class DocumentFilterContextProvider(ContextProvider):\n",
    "    def __init__(self, search_provider, allowed_titles: list[str]):\n",
    "        # TODO: Store the search provider and allowed titles\n",
    "        pass\n",
    "    \n",
    "    async def invoking(self, messages, **kwargs) -> Context:\n",
    "        # TODO: Call the search provider, then filter results\n",
    "        # to only include documents with titles in allowed_titles\n",
    "        pass\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "class DocumentFilterContextProvider(ContextProvider):\n",
    "    def __init__(self, search_provider, allowed_titles: list[str]):\n",
    "        self.search_provider = search_provider\n",
    "        self.allowed_titles = [t.lower() for t in allowed_titles]\n",
    "    \n",
    "    async def invoking(self, messages, **kwargs) -> Context:\n",
    "        # Get context from the underlying provider\n",
    "        context = await self.search_provider.invoking(messages, **kwargs)\n",
    "        \n",
    "        # Filter instructions to only include allowed sources\n",
    "        # (This is a simplified example - real filtering depends on\n",
    "        # how your provider formats the context)\n",
    "        if context.instructions:\n",
    "            lines = context.instructions.split('\\\\n')\n",
    "            filtered = [l for l in lines \n",
    "                       if any(t in l.lower() for t in self.allowed_titles)]\n",
    "            context = Context(instructions='\\\\n'.join(filtered))\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        await self.search_provider.__aenter__()\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, *args):\n",
    "        await self.search_provider.__aexit__(*args)\n",
    "\n",
    "# Usage:\n",
    "handbook_only = DocumentFilterContextProvider(\n",
    "    search_provider, \n",
    "    allowed_titles=['employee_handbook.pdf']\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-index2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if second index is configured\n",
    "load_dotenv(override=True)\n",
    "index2_name = os.getenv(\"INDEX_2_NAME\")\n",
    "\n",
    "if index2_name:\n",
    "    print(f\"✅ Second index configured: {index2_name}\")\n",
    "else:\n",
    "    print(\"⚠️ INDEX2_NAME not found in .env - complete Exercise 1 first\")\n",
    "    print(\"   You can still proceed with a single index, but the multi-source examples won't work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-provider",
   "metadata": {},
   "source": [
    "### AggregateContextProvider Implementation\n",
    "\n",
    "The `AggregateContextProvider` combines multiple context providers by:\n",
    "1. Calling `invoking()` on all providers in parallel\n",
    "2. Merging their returned contexts (instructions, messages, tools)\n",
    "3. Calling `invoked()` on all providers after the agent responds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-provider-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections.abc import MutableSequence, Sequence\n",
    "from contextlib import AsyncExitStack\n",
    "from types import TracebackType\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import ContextProvider, Context, ChatMessage\n",
    "\n",
    "\n",
    "class AggregateContextProvider(ContextProvider):\n",
    "    \"\"\"\n",
    "    A ContextProvider that combines multiple context providers.\n",
    "    \n",
    "    It delegates events to all providers and aggregates their responses.\n",
    "    This allows you to combine multiple knowledge sources into a single provider.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, providers: list[ContextProvider]):\n",
    "        self.providers = providers\n",
    "        self._exit_stack: AsyncExitStack | None = None\n",
    "    \n",
    "    async def invoking(\n",
    "        self,\n",
    "        messages: ChatMessage | MutableSequence[ChatMessage],\n",
    "        **kwargs: Any\n",
    "    ) -> Context:\n",
    "        \"\"\"Aggregate context from all providers.\"\"\"\n",
    "        # Call all providers in parallel\n",
    "        contexts = await asyncio.gather(*[\n",
    "            provider.invoking(messages, **kwargs) \n",
    "            for provider in self.providers\n",
    "        ])\n",
    "        \n",
    "        # Merge all contexts\n",
    "        instructions = \"\"\n",
    "        all_messages: list[ChatMessage] = []\n",
    "        all_tools: list = []\n",
    "        \n",
    "        for ctx in contexts:\n",
    "            if ctx.instructions:\n",
    "                instructions += ctx.instructions + \"\\n\"\n",
    "            if ctx.messages:\n",
    "                all_messages.extend(ctx.messages)\n",
    "            if ctx.tools:\n",
    "                all_tools.extend(ctx.tools)\n",
    "        \n",
    "        return Context(\n",
    "            instructions=instructions.strip() if instructions else None,\n",
    "            messages=all_messages if all_messages else None,\n",
    "            tools=all_tools if all_tools else None,\n",
    "        )\n",
    "    \n",
    "    async def invoked(\n",
    "        self,\n",
    "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
    "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
    "        invoke_exception: Exception | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Notify all providers after invocation.\"\"\"\n",
    "        await asyncio.gather(*[\n",
    "            provider.invoked(\n",
    "                request_messages=request_messages,\n",
    "                response_messages=response_messages,\n",
    "                invoke_exception=invoke_exception,\n",
    "                **kwargs,\n",
    "            )\n",
    "            for provider in self.providers\n",
    "        ])\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        \"\"\"Enter all provider contexts.\"\"\"\n",
    "        self._exit_stack = AsyncExitStack()\n",
    "        await self._exit_stack.__aenter__()\n",
    "        \n",
    "        for provider in self.providers:\n",
    "            await self._exit_stack.enter_async_context(provider)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(\n",
    "        self,\n",
    "        exc_type: type[BaseException] | None,\n",
    "        exc_val: BaseException | None,\n",
    "        exc_tb: TracebackType | None,\n",
    "    ) -> None:\n",
    "        \"\"\"Exit all provider contexts.\"\"\"\n",
    "        if self._exit_stack:\n",
    "            await self._exit_stack.__aexit__(exc_type, exc_val, exc_tb)\n",
    "            self._exit_stack = None\n",
    "\n",
    "\n",
    "print(\"AggregateContextProvider defined ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi-source-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if INDEX2_NAME is not configured\n",
    "if not index2_name:\n",
    "    print(\"Skipping multi-source example - INDEX2_NAME not configured\")\n",
    "else:\n",
    "    # Create individual providers for each knowledge source\n",
    "    health_plans_provider = AzureAISearchContextProvider(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=index_name,\n",
    "        api_key=search_key,\n",
    "        mode=\"semantic\",\n",
    "        top_k=3,\n",
    "        semantic_configuration_name=f\"{index_name}-semantic-configuration\",\n",
    "        vector_field_name=\"text_vector\",\n",
    "        embedding_function=get_embedding,\n",
    "    )\n",
    "\n",
    "    general_hr_provider = AzureAISearchContextProvider(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=index2_name,\n",
    "        api_key=search_key,\n",
    "        mode=\"semantic\",\n",
    "        top_k=3,\n",
    "        semantic_configuration_name=f\"{index2_name}-semantic-configuration\",\n",
    "        vector_field_name=\"text_vector\",\n",
    "        embedding_function=get_embedding,\n",
    "    )\n",
    "\n",
    "    # Combine providers\n",
    "    composite_provider = AggregateContextProvider([\n",
    "        health_plans_provider,\n",
    "        general_hr_provider,\n",
    "    ])\n",
    "\n",
    "    # Test questions that span both knowledge bases\n",
    "    TEST_QUESTIONS = [\n",
    "        \"What's the PerksPlus program?\",          # General HR (index2)\n",
    "        \"What is the deductible for Northwind Standard?\",  # Health plans (index1)\n",
    "        \"What benefits are available to employees?\",       # Spans both\n",
    "    ]\n",
    "\n",
    "    async with (\n",
    "        composite_provider,\n",
    "        ChatAgent(\n",
    "            chat_client=chat_client,\n",
    "            name=\"ComprehensiveHRAgent\",\n",
    "            instructions=\"\"\"\n",
    "            You are a helpful HR assistant for Contoso Electronics employees.\n",
    "\n",
    "            You have access to two knowledge bases:\n",
    "            1. **Health Plan Details**: Northwind Health Plus and Standard plan specifics\n",
    "            2. **General HR Knowledge**: Company policies, benefits overview, PerksPlus\n",
    "\n",
    "            Guidelines:\n",
    "            - Answer using ONLY the context provided\n",
    "            - Keep responses to 2-3 sentences\n",
    "            - Cite specific sources when relevant\n",
    "            \"\"\",\n",
    "            context_provider=composite_provider,\n",
    "        ) as agent,\n",
    "    ):\n",
    "        for question in TEST_QUESTIONS:\n",
    "            print(f\"\\nUser: {question}\")\n",
    "            print(\"Agent: \", end=\"\", flush=True)\n",
    "            \n",
    "            async for chunk in agent.run_stream(question):\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)\n",
    "            \n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Custom Context Providers\n",
    "\n",
    "> Ask HR is working, but it treats every employee the same. Let's make it personal - it should know who it's talking to, and be aware of time-sensitive information like enrollment periods.\n",
    "\n",
    "Custom Context Providers let you inject any context you want: user profiles, current time, extracted memories, or data from non-Azure sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-provider-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TimeAwareContextProvider(ContextProvider):\n",
    "    \"\"\"\n",
    "    A context provider that injects the current date and time.\n",
    "    \n",
    "    Useful for agents that need to understand temporal context,\n",
    "    like deadlines, enrollment periods, or time-sensitive policies.\n",
    "    \"\"\"\n",
    "    \n",
    "    async def invoking(\n",
    "        self,\n",
    "        messages: ChatMessage | MutableSequence[ChatMessage],\n",
    "        **kwargs: Any\n",
    "    ) -> Context:\n",
    "        current_time = datetime.now().strftime(\"%A, %B %d, %Y at %I:%M %p\")\n",
    "        return Context(\n",
    "            instructions=f\"Current date and time: {current_time}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class UserProfileContextProvider(ContextProvider):\n",
    "    \"\"\"\n",
    "    A context provider that injects user profile information.\n",
    "    \n",
    "    This allows personalized responses based on the user's\n",
    "    enrollment status, plan selection, or employment details.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, user_profile: dict):\n",
    "        self.user_profile = user_profile\n",
    "    \n",
    "    async def invoking(\n",
    "        self,\n",
    "        messages: ChatMessage | MutableSequence[ChatMessage],\n",
    "        **kwargs: Any\n",
    "    ) -> Context:\n",
    "        profile_text = \"\\n\".join([\n",
    "            f\"- {key}: {value}\" \n",
    "            for key, value in self.user_profile.items()\n",
    "        ])\n",
    "        return Context(\n",
    "            instructions=f\"User Profile:\\n{profile_text}\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"Custom context providers defined ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-provider-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine custom providers with search provider\n",
    "user_profile = {\n",
    "    \"Name\": \"Alice Johnson\",\n",
    "    \"Department\": \"Engineering\",\n",
    "    \"Current Plan\": \"Northwind Health Plus\",\n",
    "    \"Employment Status\": \"Full-time\",\n",
    "}\n",
    "\n",
    "time_provider = TimeAwareContextProvider()\n",
    "profile_provider = UserProfileContextProvider(user_profile)\n",
    "\n",
    "# Create a search provider for knowledge retrieval\n",
    "knowledge_provider = AzureAISearchContextProvider(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    api_key=search_key,\n",
    "    mode=\"semantic\",\n",
    "    top_k=3,\n",
    "    semantic_configuration_name=f\"{index_name}-semantic-configuration\",\n",
    "    vector_field_name=\"text_vector\",\n",
    "    embedding_function=get_embedding,\n",
    ")\n",
    "\n",
    "# Combine all providers\n",
    "combined_provider = AggregateContextProvider([\n",
    "    time_provider,\n",
    "    profile_provider,\n",
    "    knowledge_provider,\n",
    "])\n",
    "\n",
    "async with (\n",
    "    combined_provider,\n",
    "    ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"PersonalizedHRAgent\",\n",
    "        instructions=\"\"\"\n",
    "        You are a personalized HR assistant.\n",
    "        \n",
    "        Use the user profile to personalize your responses.\n",
    "        Reference their current plan when answering health questions.\n",
    "        Be aware of the current date for any time-sensitive information.\n",
    "        \"\"\",\n",
    "        context_provider=combined_provider,\n",
    "    ) as agent,\n",
    "):\n",
    "    # The agent now has access to time, user profile, AND search results\n",
    "    response = await agent.run(\"What is my deductible?\")\n",
    "    print(f\"Agent: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise2",
   "metadata": {},
   "source": [
    "### Exercise 2: Open Enrollment Awareness\n",
    "\n",
    "The `TimeAwareContextProvider` just injects the date. But what if Ask HR should **proactively mention** when open enrollment is happening?\n",
    "\n",
    "**Your task:** Create an `EnrollmentAwareProvider` that:\n",
    "1. Checks if the current date is within open enrollment period (Nov 1 - Nov 30)\n",
    "2. If so, searches for enrollment-related documents and injects them as additional context\n",
    "3. Adds an instruction reminding the agent to mention the enrollment deadline\n",
    "\n",
    "```python\n",
    "class EnrollmentAwareProvider(ContextProvider):\n",
    "    def __init__(self, search_provider):\n",
    "        self.search_provider = search_provider\n",
    "        self.enrollment_start = (11, 1)  # November 1\n",
    "        self.enrollment_end = (11, 30)   # November 30\n",
    "    \n",
    "    async def invoking(self, messages, **kwargs) -> Context:\n",
    "        now = datetime.now()\n",
    "        # TODO: Check if we're in enrollment period\n",
    "        # TODO: If yes, search for enrollment docs and add reminder\n",
    "        # TODO: If no, return empty context\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Test it:** When your provider detects enrollment season, the agent should mention the deadline even for unrelated questions like \\\"What's my deductible?\\\"\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "class EnrollmentAwareProvider(ContextProvider):\n",
    "    def __init__(self, search_provider):\n",
    "        self.search_provider = search_provider\n",
    "        self.enrollment_start = (11, 1)\n",
    "        self.enrollment_end = (11, 30)\n",
    "    \n",
    "    def _is_enrollment_period(self) -> bool:\n",
    "        now = datetime.now()\n",
    "        return (self.enrollment_start <= (now.month, now.day) <= self.enrollment_end)\n",
    "    \n",
    "    async def invoking(self, messages, **kwargs) -> Context:\n",
    "        if not self._is_enrollment_period():\n",
    "            return Context()\n",
    "        \n",
    "        # During enrollment, always inject enrollment context\n",
    "        # Force a search for enrollment info\n",
    "        enrollment_query = ChatMessage.user(\\\"open enrollment deadline benefits changes\\\")\n",
    "        enrollment_context = await self.search_provider.invoking([enrollment_query], **kwargs)\n",
    "        \n",
    "        reminder = \\\"\\\"\\\"\\nIMPORTANT: Open enrollment is currently active!\n",
    "        Deadline: November 30th. Remind users to review their benefits choices.\\\"\\\"\\\"\n",
    "        \n",
    "        instructions = (enrollment_context.instructions or \\\"\\\") + reminder\n",
    "        return Context(instructions=instructions)\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        await self.search_provider.__aenter__()\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, *args):\n",
    "        await self.search_provider.__aexit__(*args)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise3",
   "metadata": {},
   "source": [
    "### Exercise 3: Build a Memory Extraction Provider\n",
    "\n",
    "Create a custom context provider that:\n",
    "1. In `invoked()`, extracts any facts the user mentions (like preferences)\n",
    "2. In `invoking()`, injects those stored facts as context\n",
    "\n",
    "This creates a simple long-term memory for the agent.\n",
    "\n",
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "class SimpleMemoryProvider(ContextProvider):\n",
    "    \"\"\"A context provider that extracts and remembers user facts.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memories: list[str] = []\n",
    "    \n",
    "    async def invoking(\n",
    "        self,\n",
    "        messages: ChatMessage | MutableSequence[ChatMessage],\n",
    "        **kwargs: Any\n",
    "    ) -> Context:\n",
    "        if not self.memories:\n",
    "            return Context()\n",
    "        \n",
    "        memory_text = \"\\n\".join([f\"- {m}\" for m in self.memories])\n",
    "        return Context(\n",
    "            instructions=f\"Remembered facts about the user:\\n{memory_text}\"\n",
    "        )\n",
    "    \n",
    "    async def invoked(\n",
    "        self,\n",
    "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
    "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        # Simple extraction: look for \"I prefer\" or \"I like\" statements\n",
    "        msgs = [request_messages] if isinstance(request_messages, ChatMessage) else list(request_messages)\n",
    "        \n",
    "        for msg in msgs:\n",
    "            content = str(msg.content).lower()\n",
    "            if \"i prefer\" in content or \"i like\" in content:\n",
    "                self.memories.append(str(msg.content))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Ask HR is now production-ready.** You started with 30+ lines of manual RAG boilerplate in 03.1, and now you have a personalized, time-aware HR assistant in ~10 lines of configuration.\n",
    "\n",
    "The journey:\n",
    "1. **Built-in RAG** - `AzureAISearchContextProvider` handles search automatically\n",
    "2. **Multi-source knowledge** - `AggregateContextProvider` combines health plans + company policies\n",
    "3. **Personalization** - Custom providers inject user profiles, time, and memories\n",
    "\n",
    "The key insight: Context Providers are middleware. They run `invoking()` before the LLM sees your message (to inject context) and `invoked()` after (to extract and store information). This pattern - inject before, extract after - is the foundation of intelligent agents.\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In Chapter 4, you'll give Ask HR the ability to **take action** - not just answer questions, but actually help employees change their benefits, submit requests, and interact with external systems.\n",
    "\n",
    "### Going Deeper\n",
    "\n",
    "The Agent Framework has additional context providers we didn't cover: Mem0 for long-term memory, Redis for fast retrieval, and agentic search for multi-hop reasoning. See the [samples directory](https://github.com/microsoft/agent-framework/tree/main/python/samples/getting_started/context_providers) for examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
